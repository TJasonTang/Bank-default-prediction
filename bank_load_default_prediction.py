# -*- coding: utf-8 -*-
"""Bank load Default Prediction

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lFru4Zq_MaJwMUJZYZv6DRF5_Pf5XPqr

# Bank load Default Prediction

##Libraries
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix



"""## 1.Loading Data"""

df = pd.read_excel("/content/bank_loan_dataset(3100).xlsx")  #Change this to your Path Mr Lee

"""## 2.Summarize the data to understand its characteristics."""

df.head()

# Rename columns using the second row and drop the first two rows
df.columns = df.iloc[1]
df = df.drop([0, 1]).reset_index(drop=True)

df.head()

df.info()

# Display summary of the data
summary = df.describe(include='all')
summary

# There are 5,000 unique Customer_ID entries, indicating no duplicates in the dataset.

# Most columns are categorical in nature, as evidenced by the presence of unique values, top categories, and frequencies.

# The Default_On_Payment column is our target variable. It has two unique values: 0 (no default) and 1 (default). There are 3,505 instances with a value of 0, which suggests a somewhat imbalanced dataset.

# The Count column has a single value of 1 across all rows, making it redundant for analysis or modeling purposes.

"""## 3.Data preprocessing

### Check Missing Values
"""

# Check for missing values
missing_values = df.isnull().sum()
missing_values

"""### Drop redundant columns"""

# Drop the redundant 'Count' column
df = df.drop(columns='Count')

"""### One-Hot encoding"""

# Correctly identifying the numeric and categorical columns
correct_numeric_cols = ['Customer_ID', 'Duration_in_Months', 'Credit_Amount', 'Inst_Rt_Income',
                        'Current_Address_Yrs', 'Age', 'Num_CC', 'Dependents', 'Default_On_Payment']
correct_categorical_cols = [col for col in df.columns if col not in correct_numeric_cols]

# Applying one-hot encoding only to the correct categorical columns
df_categorical_correct = df[correct_categorical_cols]
df_categorical_encoded_correct = pd.get_dummies(df_categorical_correct)

# Combining the correctly identified numeric columns and the encoded categorical columns
df_correctly_encoded = pd.concat([df[correct_numeric_cols], df_categorical_encoded_correct], axis=1)

df_correctly_encoded.shape



"""## 4.Exploratory Data Analysis

### Stats overview
"""

# Summary statistics for numeric features
numeric_summary = df[correct_numeric_cols].describe()

# Summary statistics for categorical features
categorical_summary = df[correct_categorical_cols].describe(include='object')

numeric_summary, categorical_summary

# Summerise
# Numeric Features:
# Duration_in_Months: Most loans have a duration of 24 months.
# Credit_Amount: The most frequent credit amount is 1478 (though this could change with different datasets).
# Inst_Rt_Income: The most common installment rate as a fraction of disposable income is 4.
# Current_Address_Yrs: Most applicants have been at their current address for 4 years.
# Age: The most frequent age is 27.
# Num_CC: The majority of applicants have 1 existing credit at the bank.
# Dependents: Most applicants have 1 dependent.
# Default_On_Payment: 3505 out of 5000 applicants did not default on their payment.
# Count: This seems to be a constant column with the value of 1 for all entries. It doesn't provide any meaningful information and can be dropped.

# Categorical Features:
# Status_Checking_Acc: 'A14' is the most frequent category.
# Credit_History: 'A32' is the most frequent category.
# Purposre_Credit_Taken: 'A43' is the most frequent purpose.
# Savings_Acc: 'A61' is the most common savings account category.
# Years_At_Present_Employment: 'A73' is the most common category.
# Marital_Status_Gender: 'A93' is the most frequent category.

"""### Visualization

#### Numerical features
"""

# Visualizing the distribution of numeric variables
plt.figure(figsize=(20, 15))

for i, col in enumerate(correct_numeric_cols, 1):
    if col != "Default_On_Payment":  # excluding target variable from distribution plots
        plt.subplot(3, 3, i)
        sns.histplot(df[col], kde=True, bins=30)
        plt.title(f'Distribution of {col}')
        plt.tight_layout()

plt.show()

# Duration_in_Months: Most loans have shorter durations, with a spike around 24 months.
# Credit_Amount: The distribution is right-skewed, with most loans being of smaller amounts.
# Inst_Rt_Income: Most of the data points are clustered around 1 and 4, indicating specific common installment rates.
# Current_Address_Yrs: A significant number of people have been at their current address for 4 years.
# Age: The distribution is slightly right-skewed, indicating that younger people are more represented in the dataset.
# Num_CC: Most people have 1 or 2 credits with the bank.
# Dependents: A vast majority have only 1 dependent.

# Visualizing the relationship between numeric features and the target variable using boxplots
plt.figure(figsize=(20, 15))

for i, col in enumerate(correct_numeric_cols, 1):
    if col != "Default_On_Payment":  # excluding target variable from boxplots
        plt.subplot(3, 3, i)
        sns.boxplot(x=df["Default_On_Payment"], y=df[col])
        plt.title(f'Relationship of {col} with Default on Payment')
        plt.tight_layout()

plt.show()

# Duration_in_Months: Loans that default tend to have a slightly higher median duration.
# Credit_Amount: Loans that default also seem to have a slightly higher median credit amount.
# Inst_Rt_Income: The distribution of installment rates seems roughly similar for both default and non-default loans.
# Current_Address_Yrs: The number of years at the current address doesn't show a strong differentiation between the default and non-default groups.
# Age: Younger individuals appear to have a slightly higher tendency to default, as indicated by the lower median age for the default group.
# Num_CC: The number of credits at this bank doesn't show a strong differentiation between the default and non-default groups.
# Dependents: The number of dependents doesn't show a significant difference between the two groups.

"""#### Categorical features"""

# Visualizing the relationship between categorical features and the target variable
plt.figure(figsize=(20, 20))

# We'll visualize only the first 9 categorical columns for brevity.
# If needed, we can visualize the rest in subsequent plots.
for i, col in enumerate(correct_categorical_cols[:9], 1):
    plt.subplot(3, 3, i)
    sns.countplot(data=df, x=col, hue='Default_On_Payment', order=df[col].value_counts().index)
    plt.title(f'{col} vs Default_On_Payment')
    plt.xticks(rotation=45)
    plt.tight_layout()

plt.show()

# Status_Checking_Acc: The 'A14' category seems to have a lower proportion of defaults compared to the other categories.
# Credit_History: The 'A34' category (critical/other existing credit) has a lower proportion of defaults.
# Purpose_Credit_Taken: While there are variations in the number of loans taken for each purpose, the proportion of defaults seems relatively consistent across purposes. However, 'A40' (car - new) and 'A49' (education) seem to have a slightly higher default rate.
# Savings_Acc: Those with category 'A65' (unknown/no savings account) seem to have a lower default rate.
# Years_At_Present_Employment: The default rate seems consistent across different employment durations.
# Marital_Status_Gender: Males (single) - 'A93' seem to have a higher default rate.
# Other_Debtors_Guarantors: The default rate seems consistent across categories.
# Property: Those with category 'A124' (unknown/no property) seem to have a slightly higher default rate.
# Other_Inst_Plans: The default rate seems relatively consistent across categories.

"""### Correlation of each features to Target"""

# Converting the numeric columns to appropriate data types
for col in correct_numeric_cols:
    df[col] = df[col].astype(float)

# correlation matrix
numeric_corr_matrix = df[correct_numeric_cols].corr()

# Extracting correlations with the target variable for numeric features
numeric_correlations_with_target = numeric_corr_matrix["Default_On_Payment"].drop("Default_On_Payment")

# Calculating point-biserial correlation for categorical features
categorical_correlations_with_target = []
for col in df_categorical_encoded_correct.columns:
    correlation = df["Default_On_Payment"].corr(df_categorical_encoded_correct[col])
    categorical_correlations_with_target.append((col, correlation))

categorical_correlations_with_target = pd.Series(dict(categorical_correlations_with_target))

# Combining the numeric and categorical correlations
combined_correlations = pd.concat([numeric_correlations_with_target, categorical_correlations_with_target], axis=0)
combined_correlations_sorted = combined_correlations.abs().sort_values(ascending=False)

combined_correlations_sorted

# Status_Checking_Acc_A14" and "Status_Checking_Acc_A11", have a relatively strong correlation with the target variable.



"""##  5.Model Trainning

### Data splitting
"""

# Splitting the corrected data into training and test sets
X_corrected_final = df_correctly_encoded.drop(columns=["Default_On_Payment"])
y_corrected_final = df_correctly_encoded["Default_On_Payment"].astype(int)  # Converting target to integer type
X_train_final, X_test_final, y_train_final, y_test_final = train_test_split(X_corrected_final, y_corrected_final, test_size=0.2, random_state=42, stratify=y_corrected_final)

"""### Trying Models"""

from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier

# Initializing the models
models = {
    "Logistic Regression": LogisticRegression(max_iter=1000, random_state=42),
    "Decision Tree": DecisionTreeClassifier(random_state=42),
    "Random Forest": RandomForestClassifier(random_state=42),
    "Gradient Boosting": GradientBoostingClassifier(random_state=42),
    "SVM": SVC(random_state=42),
    "KNN": KNeighborsClassifier()
}

# Training and evaluating each model
model_accuracies = {}

for name, model in models.items():
    model.fit(X_train_final, y_train_final)
    predictions = model.predict(X_test_final)
    accuracy = accuracy_score(y_test_final, predictions)
    model_accuracies[name] = accuracy

model_accuracies

# Gradient boosting achived the best, Decision tree ramdom forest has perfect score which is not possible, so it is not reliable.

"""### Imbalance (Oversampling)"""

from sklearn.utils import resample

# Separate the majority and minority classes in the training data
df_train = pd.concat([X_train_final, y_train_final], axis=1)
majority_class = df_train[df_train.Default_On_Payment == 0]
minority_class = df_train[df_train.Default_On_Payment == 1]

# Oversample the minority class
minority_class_oversampled = resample(minority_class,
                                      replace=True,
                                      n_samples=len(majority_class),
                                      random_state=42)

# Combine the majority class with the oversampled minority class
df_train_oversampled = pd.concat([majority_class, minority_class_oversampled])

# Splitting the oversampled data back into X and y for training
X_train_oversampled = df_train_oversampled.drop("Default_On_Payment", axis=1)
y_train_oversampled = df_train_oversampled.Default_On_Payment

y_train_oversampled.value_counts()

"""### Retraining Model after oversampling"""

# Train the Gradient Boosting classifier on the oversampled data
gb_classifier_oversampled = GradientBoostingClassifier(random_state=42)
gb_classifier_oversampled.fit(X_train_oversampled, y_train_oversampled)

# Predict on the test set
gb_predictions_oversampled = gb_classifier_oversampled.predict(X_test_final)

# Calculate accuracy for Gradient Boosting on the oversampled data
gb_accuracy_oversampled = accuracy_score(y_test_final, gb_predictions_oversampled)

gb_accuracy_oversampled

"""## 6.Model evaluation

### Grid search to find the best Parameters
"""

from sklearn.model_selection import GridSearchCV
param_grid = {
    'n_estimators': [50, 100],
    'learning_rate': [0.01, 0.1],
    'max_depth': [3, 5]
}

gb_grid_search = GridSearchCV(GradientBoostingClassifier(random_state=42), param_grid, cv=3, n_jobs=-1, verbose=2)
gb_grid_search.fit(X_train_oversampled, y_train_oversampled)

# Best hyperparameters from the grid search
best_params = gb_grid_search.best_params_

best_params

"""### Train model with best Parameters"""

# Training the Gradient Boosting classifier using the best hyperparameters
best_gb_classifier = GradientBoostingClassifier(
    learning_rate=0.1,
    max_depth=5,
    n_estimators=100,
    random_state=42
)
best_gb_classifier.fit(X_train_oversampled, y_train_oversampled)

# Predicting on the test set
best_gb_predictions = best_gb_classifier.predict(X_test_final)

# Calculating accuracy for the best Gradient Boosting model
best_gb_accuracy = accuracy_score(y_test_final, best_gb_predictions)

best_gb_accuracy

from sklearn.model_selection import learning_curve

# Determine the training and test scores for varying training set sizes
train_sizes, train_scores, test_scores = learning_curve(
    best_gb_classifier, X_corrected_final, y_corrected_final, cv=5, n_jobs=-1,
    train_sizes=np.linspace(0.1, 1.0, 10), random_state=42)

# Calculate the mean and standard deviation for training and test sets
train_mean = np.mean(train_scores, axis=1)
train_std = np.std(train_scores, axis=1)
test_mean = np.mean(test_scores, axis=1)
test_std = np.std(test_scores, axis=1)

# Plot the learning curve
plt.figure(figsize=(10, 6))
plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, color="r", alpha=0.1)
plt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, color="g", alpha=0.1)
plt.plot(train_sizes, train_mean, 'o-', color="r", label="Training score")
plt.plot(train_sizes, test_mean, 'o-', color="g", label="Cross-validation score")
plt.title("Learning Curve for Gradient Boosting Classifier")
plt.xlabel("Training Set Size")
plt.ylabel("Accuracy Score")
plt.legend(loc="best")
plt.grid()
plt.show()

# The gap between the two curves decreases as the training set size increases,
# suggesting that the model is generalizing well and is not overfitting.

"""### Confusion Matrix"""

from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, ConfusionMatrixDisplay

# Calculating other metrics
precision = precision_score(y_test_final, best_gb_predictions)
recall = recall_score(y_test_final, best_gb_predictions)
f1 = f1_score(y_test_final, best_gb_predictions)
roc_auc = roc_auc_score(y_test_final, best_gb_predictions)

# Confusion Matrix
cm = confusion_matrix(y_test_final, best_gb_predictions)
cm_display = ConfusionMatrixDisplay(cm).plot()

precision, recall, f1, roc_auc

# Based on the confusion matrix and the metrics, the Gradient Boosting classifier performs well on this dataset. The model has a good balance of precision and recall, making it suitable for this kind of prediction where both false negatives (missing a default) and false positives (wrongly predicting a default) are costly.

"""## 7.Saving & loading model"""

import joblib

# Save the Gradient Boosting model to a file
model_filename = "gradient_boosting_model.pkl"
joblib.dump(best_gb_classifier, model_filename)

loaded_model = joblib.load(model_filename)

"""## 8.Demo for predicting whether a loan will default or not"""

def preprocess_input(user_input):
    """
    Preprocesses the user input to prepare it for prediction.

    Parameters:
    - user_input (dict): Dictionary containing the user input for each feature.

    Returns:
    - pd.Series: A series suitable for prediction using the trained model.
    """

    # Convert user input to dataframe
    input_df = pd.DataFrame([user_input])

    # One-hot encode the categorical features
    input_df_encoded = pd.get_dummies(input_df)

    # Ensure the input has the same columns as the training data (X_corrected_final), fill missing columns with 0
    for col in X_corrected_final.columns:
        if col not in input_df_encoded.columns:
            input_df_encoded[col] = 0

    # Reorder columns to match the training data
    input_df_encoded = input_df_encoded[X_corrected_final.columns]

    return input_df_encoded.iloc[0]

# Test the preprocessing function
sample_input = {
    'Duration_in_Months': 24,
    'Credit_Amount': 2000,
    'Inst_Rt_Income': 2,
    'Current_Address_Yrs': 3,
    'Age': 35,
    'Num_CC': 1,
    'Dependents': 1,
    'Status_Checking_Acc': 'A11',
    'Credit_History': 'A34',
    'Purpose': 'A43',
    'Savings_Acc': 'A65',
    'Years_At_Present_Employment': 'A75',
    'Marital_Status_Gender': 'A93',
    'Other_Debtors_Guarantors': 'A101',
    'Property': 'A121',
    'Other_Inst_Plans': 'A143',
    'Housing': 'A152',
    'Job': 'A173',
    'Telephone': 'A192',
    'Foreign_Worker': 'A201'
}

preprocessed_sample_input = preprocess_input(sample_input)
preprocessed_sample_input

def predict_loan_default(user_input):
    """
    Predicts whether a loan will default based on user input.

    Parameters:
    - user_input (dict): Dictionary containing the user input for each feature.

    Returns:
    - str: A string indicating whether the loan will default or not.
    """

    # Preprocess the user input
    preprocessed_input = preprocess_input(user_input)

    # Make a prediction using the trained model
    prediction = loaded_model.predict([preprocessed_input])[0]

    # Convert prediction to string output
    if prediction == 1:
        return "The loan is predicted to default."
    else:
        return "The loan is predicted to be safe."

# Test the prediction function with the sample input
predict_loan_default(sample_input)